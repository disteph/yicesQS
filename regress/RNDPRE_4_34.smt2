(set-info :smt-lib-version 2.6)
(set-logic BV)
(set-info :source |
   Scholl, Christoph; Disch, Stefan; Pigorsch, Florian and Kupferschmid, 
   Stefan; Using an SMT Solver and Craig Interpolation to Detect and Remove 
   Redundant Linear Constraints in Representations of Non-Convex Polyhedra.
   Proceedings of 6th International Workshop on Satisfiability Modulo
   Theories, Princeton, USA, July 2008.
   <http://abs.informatik.uni-freiburg.de/smtbench/>

Translated to BV by Mathias Preiner.
|)
(set-info :license "https://creativecommons.org/licenses/by/4.0/")
(set-info :category "random")
(set-info :status unknown)
(declare-fun x1 () (_ BitVec 32))
(declare-fun x2 () (_ BitVec 32))
(declare-fun x3 () (_ BitVec 32))
(declare-fun x4 () (_ BitVec 32))
(assert (forall ((?x1 (_ BitVec 32))) (exists ((?x2 (_ BitVec 32))) (forall ((?x3 (_ BitVec 32))) (exists ((?x4 (_ BitVec 32))) (let ((?v_1 (bvmul (_ bv15 32) ?x4)) (?v_3 (bvmul (_ bv2 32) ?x4)) (?v_11 (bvmul (_ bv83 32) ?x1)) (?v_6 (bvmul (_ bv65 32) ?x3)) (?v_4 (bvmul (_ bv98 32) ?x4)) (?v_5 (bvmul (_ bv5 32) ?x4)) (?v_10 (bvmul (_ bv74 32) ?x2)) (?v_8 (bvmul (bvneg (_ bv22 32)) ?x3)) (?v_0 (bvmul (bvneg (_ bv39 32)) ?x2)) (?v_2 (bvmul (bvneg (_ bv36 32)) ?x1)) (?v_7 (bvmul (bvneg (_ bv54 32)) ?x4)) (?v_9 (bvmul (bvneg (_ bv38 32)) ?x3)) (?v_12 (bvmul (bvneg (_ bv76 32)) ?x2))) (or (or (and (or (or (bvsge (bvadd (bvmul (_ bv61 32) ?x1) ?v_8) (_ bv49 32)) (not (= (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv94 32)) ?x1) (bvmul (bvneg (_ bv60 32)) ?x2)) (bvmul (_ bv78 32) ?x3)) (bvmul (bvneg (_ bv31 32)) ?x4)) (_ bv30 32)))) (and (or (= (bvmul (_ bv51 32) ?x1) (bvneg (_ bv60 32))) (not (= (bvadd (bvadd (bvmul (bvneg (_ bv92 32)) ?x1) (bvmul (_ bv11 32) ?x2)) (bvmul (_ bv84 32) ?x4)) (_ bv0 32)))) (and (bvsle (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv26 32)) ?x1) (bvmul (_ bv50 32) ?x2)) (bvmul (bvneg (_ bv35 32)) ?x3)) (bvmul (bvneg (_ bv100 32)) ?x4)) (bvneg (_ bv81 32))) (= (bvadd (bvadd (bvmul (bvneg (_ bv68 32)) ?x1) (bvmul (bvneg (_ bv15 32)) ?x2)) (bvmul (_ bv43 32) ?x4)) (_ bv33 32))))) (or (or (or (bvsgt (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv51 32)) ?x1) ?v_0) (bvmul (_ bv86 32) ?x3)) (bvmul (bvneg (_ bv88 32)) ?x4)) (_ bv80 32)) (bvslt (bvadd (bvmul (bvneg (_ bv39 32)) ?x1) (bvmul (bvneg (_ bv38 32)) ?x4)) (bvneg (_ bv47 32)))) (and (bvslt (bvadd (bvadd (bvmul (bvneg (_ bv95 32)) ?x1) (bvmul (bvneg (_ bv54 32)) ?x2)) (bvmul (bvneg (_ bv95 32)) ?x3)) (bvneg (_ bv17 32))) (not (= (bvadd (bvadd ?v_2 (bvmul (bvneg (_ bv52 32)) ?x2)) (bvmul (_ bv53 32) ?x3)) (_ bv0 32))))) (and (= (bvadd (bvadd (bvmul (_ bv98 32) ?x1) (bvmul (_ bv7 32) ?x2)) (bvmul (_ bv100 32) ?x4)) (bvneg (_ bv94 32))) (and (bvslt (bvadd (bvadd (bvadd (bvmul (_ bv42 32) ?x1) (bvmul (_ bv85 32) ?x2)) (bvmul (_ bv79 32) ?x3)) ?v_1) (bvneg (_ bv17 32))) (= (bvadd (bvadd (bvmul (bvneg (_ bv55 32)) ?x1) (bvmul (bvneg (_ bv90 32)) ?x2)) (bvmul (_ bv1 32) ?x4)) (bvneg (_ bv36 32))))))) (or (and (and (bvslt (bvadd (bvmul (bvneg (_ bv17 32)) ?x2) (bvmul (_ bv69 32) ?x4)) (_ bv0 32)) (and (not (= (bvadd (bvadd (bvmul (_ bv49 32) ?x1) (bvmul (bvneg (_ bv59 32)) ?x2)) (bvmul (_ bv81 32) ?x4)) (_ bv0 32))) (= (bvadd (bvadd (bvadd (bvmul (_ bv30 32) ?x1) (bvmul (_ bv10 32) ?x2)) (bvmul (bvneg (_ bv57 32)) ?x3)) ?v_7) (_ bv36 32)))) (and (or (bvsgt (bvadd (bvmul (bvneg (_ bv22 32)) ?x2) ?v_9) (bvneg (_ bv55 32))) (not (= (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv24 32)) ?x1) (bvmul (_ bv84 32) ?x2)) (bvmul (_ bv49 32) ?x3)) ?v_3) (bvneg (_ bv73 32))))) (or (bvslt (bvadd (bvadd (bvmul (bvneg (_ bv83 32)) ?x1) ?v_0) (bvmul (bvneg (_ bv36 32)) ?x3)) (bvneg (_ bv23 32))) (bvsgt (bvadd (bvadd (bvmul (_ bv44 32) ?x1) (bvmul (_ bv75 32) ?x2)) (bvmul (bvneg (_ bv14 32)) ?x3)) (_ bv5 32))))) (and (or (or (bvslt (bvadd (bvadd (bvmul (bvneg (_ bv97 32)) ?x1) (bvmul (_ bv91 32) ?x3)) ?v_1) (bvneg (_ bv59 32))) (bvsle (bvadd (bvadd ?v_11 ?v_12) (bvmul (bvneg (_ bv4 32)) ?x3)) (_ bv0 32))) (and (bvsge (bvadd (bvadd (bvadd ?v_2 (bvmul (bvneg (_ bv26 32)) ?x2)) ?v_6) ?v_3) (_ bv0 32)) (bvsgt (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv3 32)) ?x1) (bvmul (bvneg (_ bv70 32)) ?x2)) (bvmul (_ bv4 32) ?x3)) (bvmul (_ bv86 32) ?x4)) (bvneg (_ bv40 32))))) (and (bvsle (bvadd (bvmul (_ bv27 32) ?x1) (bvmul (_ bv16 32) ?x4)) (_ bv95 32)) (or (bvslt (bvadd (bvadd (bvmul (_ bv93 32) ?x2) (bvmul (_ bv36 32) ?x3)) (bvmul (_ bv96 32) ?x4)) (_ bv82 32)) (bvsgt (bvadd (bvmul (bvneg (_ bv88 32)) ?x3) (bvmul (_ bv63 32) ?x4)) (_ bv89 32))))))) (and (and (and (or (or (and (bvslt (bvadd (bvadd (bvadd (bvmul (_ bv32 32) ?x1) (bvmul (_ bv63 32) ?x2)) (bvmul (_ bv48 32) ?x3)) ?v_4) (bvneg (_ bv8 32))) (not (= (bvadd (bvadd (bvmul (_ bv24 32) ?x2) (bvmul (_ bv88 32) ?x3)) ?v_5) (bvneg (_ bv78 32))))) (and (bvsge (bvadd (bvadd (bvadd (bvmul (_ bv12 32) ?x1) (bvmul (_ bv8 32) ?x2)) (bvmul (_ bv85 32) ?x3)) (bvmul (_ bv71 32) ?x4)) (_ bv94 32)) (bvsgt (bvadd (bvmul (_ bv67 32) ?x1) (bvmul (_ bv45 32) ?x2)) (_ bv0 32)))) (and (bvslt (bvadd (bvmul (bvneg (_ bv2 32)) ?x1) ?v_4) (_ bv76 32)) (bvsle (bvadd (bvadd (bvmul (_ bv86 32) ?x2) (bvmul (bvneg (_ bv44 32)) ?x3)) ?v_5) (_ bv24 32)))) (and (or (bvslt (bvadd (bvadd (bvadd (bvmul (_ bv24 32) ?x1) (bvmul (bvneg (_ bv35 32)) ?x2)) (bvmul (bvneg (_ bv75 32)) ?x3)) (bvmul (bvneg (_ bv7 32)) ?x4)) (bvneg (_ bv44 32))) (bvsgt (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv44 32)) ?x1) (bvmul (bvneg (_ bv77 32)) ?x2)) (bvmul (bvneg (_ bv91 32)) ?x3)) (bvmul (_ bv40 32) ?x4)) (_ bv32 32))) (and (or (bvsle (bvadd ?v_6 (bvmul (_ bv79 32) ?x4)) (bvneg (_ bv88 32))) (bvsgt (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv65 32)) ?x1) (bvmul (bvneg (_ bv37 32)) ?x2)) (bvmul (_ bv54 32) ?x3)) ?v_7) (_ bv0 32))) (or (= (bvadd (bvadd (bvmul (_ bv6 32) ?x1) (bvmul (bvneg (_ bv83 32)) ?x2)) (bvmul (_ bv60 32) ?x3)) (bvneg (_ bv79 32))) (= (bvadd (bvadd (bvmul (bvneg (_ bv85 32)) ?x1) ?v_10) (bvmul (_ bv81 32) ?x3)) (_ bv0 32)))))) (or (or (and (= (bvadd ?v_8 (bvmul (bvneg (_ bv48 32)) ?x4)) (_ bv12 32)) (bvsge (bvadd (bvadd (bvadd (bvmul (_ bv17 32) ?x1) (bvmul (_ bv42 32) ?x2)) ?v_9) (bvmul (_ bv25 32) ?x4)) (bvneg (_ bv62 32)))) (or (not (= (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv59 32)) ?x1) (bvmul (bvneg (_ bv28 32)) ?x2)) (bvmul (bvneg (_ bv83 32)) ?x3)) (bvmul (_ bv14 32) ?x4)) (_ bv0 32))) (or (bvsle (bvadd (bvmul (_ bv100 32) ?x3) (bvmul (bvneg (_ bv57 32)) ?x4)) (bvneg (_ bv22 32))) (bvsge (bvadd (bvmul (bvneg (_ bv15 32)) ?x1) (bvmul (_ bv41 32) ?x2)) (_ bv7 32))))) (and (and (or (bvsgt (bvadd (bvadd (bvadd (bvmul (_ bv21 32) ?x1) (bvmul (_ bv82 32) ?x2)) (bvmul (bvneg (_ bv12 32)) ?x3)) (bvmul (bvneg (_ bv24 32)) ?x4)) (bvneg (_ bv39 32))) (bvsge (bvadd (bvadd (bvmul (_ bv62 32) ?x1) ?v_10) (bvmul (bvneg (_ bv77 32)) ?x4)) (_ bv67 32))) (= (bvadd (bvmul (bvneg (_ bv29 32)) ?x3) ?v_4) (_ bv54 32))) (and (and (not (= (bvadd (bvmul (_ bv15 32) ?x1) (bvmul (_ bv73 32) ?x3)) (_ bv45 32))) (bvsle (bvadd (bvadd (bvmul (_ bv2 32) ?x1) (bvmul (_ bv90 32) ?x2)) (bvmul (bvneg (_ bv28 32)) ?x4)) (bvneg (_ bv73 32)))) (and (bvslt (bvadd (bvadd (bvadd ?v_11 (bvmul (_ bv21 32) ?x2)) (bvmul (bvneg (_ bv71 32)) ?x3)) (bvmul (_ bv34 32) ?x4)) (_ bv0 32)) (bvsge (bvadd (bvadd (bvmul (_ bv15 32) ?x2) (bvmul (bvneg (_ bv47 32)) ?x3)) (bvmul (_ bv44 32) ?x4)) (_ bv25 32))))))) (and (or (and (not (= (bvadd (bvadd (bvadd (bvmul (_ bv50 32) ?x1) (bvmul (_ bv16 32) ?x2)) (bvmul (bvneg (_ bv46 32)) ?x3)) (bvmul (bvneg (_ bv64 32)) ?x4)) (_ bv63 32))) (or (bvsle (bvadd (bvmul (_ bv76 32) ?x1) (bvmul (bvneg (_ bv56 32)) ?x2)) (_ bv51 32)) (= (bvadd (bvadd (bvmul (bvneg (_ bv78 32)) ?x2) (bvmul (bvneg (_ bv69 32)) ?x3)) (bvmul (bvneg (_ bv78 32)) ?x4)) (_ bv39 32)))) (or (bvsgt (bvadd (bvadd (bvmul (bvneg (_ bv74 32)) ?x1) ?v_6) (bvmul (_ bv17 32) ?x4)) (_ bv0 32)) (not (= (bvadd (bvmul (_ bv96 32) ?x1) (bvmul (bvneg (_ bv72 32)) ?x4)) (bvneg (_ bv3 32)))))) (or (or (= (bvadd (bvadd (bvadd (bvmul (_ bv75 32) ?x1) (bvmul (_ bv51 32) ?x2)) (bvmul (_ bv44 32) ?x3)) (bvmul (bvneg (_ bv55 32)) ?x4)) (_ bv0 32)) (= (bvadd (bvadd (bvadd (bvmul (_ bv33 32) ?x1) ?v_12) (bvmul (bvneg (_ bv99 32)) ?x3)) (bvmul (bvneg (_ bv93 32)) ?x4)) (bvneg (_ bv55 32)))) (and (or (bvslt (bvadd (bvadd (bvmul (_ bv9 32) ?x1) (bvmul (bvneg (_ bv73 32)) ?x2)) (bvmul (bvneg (_ bv60 32)) ?x3)) (_ bv34 32)) (bvsle (bvadd (bvadd (bvmul (bvneg (_ bv12 32)) ?x2) (bvmul (bvneg (_ bv86 32)) ?x3)) (bvmul (bvneg (_ bv58 32)) ?x4)) (bvneg (_ bv87 32)))) (= (bvadd (bvadd (bvmul (_ bv27 32) ?x2) (bvmul (_ bv30 32) ?x3)) (bvmul (bvneg (_ bv45 32)) ?x4)) (bvneg (_ bv67 32))))))))))))))
(check-sat)
(exit)
